# ğŸš€ AI & Automation Ecosystem â€” AtenciÃ³n al Cliente Aumentada por IA

## Ãndice

- [VisiÃ³n General](#visiÃ³n-general)
- [Diagrama de Arquitectura](#diagrama-de-arquitectura)
- [Stack TecnolÃ³gico](#stack-tecnolÃ³gico)
- [Despliegue RÃ¡pido](#despliegue-rÃ¡pido)
- [Estructura del Repositorio](#estructura-del-repositorio)
- [ConfiguraciÃ³n Detallada](#configuraciÃ³n-detallada)
- [AnÃ¡lisis de Recursos (Stress Test)](#anÃ¡lisis-de-recursos-stress-test)
- [Estrategia de ProducciÃ³n (HA)](#estrategia-de-producciÃ³n-ha)
- [OperaciÃ³n y Mantenimiento](#operaciÃ³n-y-mantenimiento)
- [Seguridad](#seguridad)
- [Troubleshooting](#troubleshooting)

---

## VisiÃ³n General

Este proyecto despliega un MVP (Sandbox) funcional de un ecosistema de **AtenciÃ³n al Cliente Aumentada por IA** en AWS, orquestando cuatro servicios principales mediante contenedores Docker:

| Servicio | FunciÃ³n | Base de Datos |
|----------|---------|---------------|
| **N8n** | Orquestador de workflows | SQLite (embebida) |
| **Chatwoot** | Plataforma de chat omnicanal | PostgreSQL + Redis |
| **LibreChat** | Interfaz unificada multi-LLM | MongoDB |
| **Jupyter Connector** | Puente de datos para Deepnote | â€” (consume las demÃ¡s) |

El despliegue es **100% automatizado** mediante AWS CloudFormation y diseÃ±ado con patrones de producciÃ³n desde el dÃ­a uno.

---

## Diagrama de Arquitectura

### Sandbox (Monolito en EC2)

```
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚          INTERNET                â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                               â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                               â”‚   Security    â”‚
                               â”‚    Groups     â”‚
                               â”‚  :80 :443 :22 â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚        EC2 Instance (t3.micro)          â”‚
                    â”‚        VPC: 10.0.0.0/16                 â”‚
                    â”‚        Subnet: 10.0.1.0/24 (public-a)  â”‚
                    â”‚                                         â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                    â”‚  â”‚     NGINX Reverse Proxy (:80)      â”‚ â”‚
                    â”‚  â”‚   /n8n  /chatwoot  /chat  /data    â”‚ â”‚
                    â”‚  â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â”‚
                    â”‚     â”‚        â”‚         â”‚        â”‚       â”‚
                    â”‚  â”Œâ”€â”€â–¼â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ–¼â”€â”€â”€â”€â”€â” â”Œâ–¼â”€â”€â”€â”€â” â”‚
                    â”‚  â”‚ N8n â”‚ â”‚Chatwoot â”‚ â”‚Libre â”‚ â”‚Jupy â”‚ â”‚
                    â”‚  â”‚:5678â”‚ â”‚Web :3000â”‚ â”‚Chat  â”‚ â”‚ter  â”‚ â”‚
                    â”‚  â””â”€â”€â”¬â”€â”€â”˜ â”‚Sidekiq  â”‚ â”‚:3080 â”‚ â”‚:8888â”‚ â”‚
                    â”‚     â”‚    â””â”€â”€â”¬â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”˜ â”‚
                    â”‚     â”‚       â”‚  â”‚        â”‚        â”‚     â”‚
                    â”‚  â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”  â”‚
                    â”‚  â”‚      BACKEND NETWORK (internal)   â”‚  â”‚
                    â”‚  â”‚                                    â”‚  â”‚
                    â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
                    â”‚  â”‚ â”‚PostgreSQLâ”‚ â”‚MongoDBâ”‚ â”‚ Redis â”‚  â”‚  â”‚
                    â”‚  â”‚ â”‚  :5432   â”‚ â”‚ :27017â”‚ â”‚ :6379 â”‚  â”‚  â”‚
                    â”‚  â”‚ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”˜  â”‚  â”‚
                    â”‚  â”‚      â”‚           â”‚         â”‚       â”‚  â”‚
                    â”‚  â”‚   [Volume]    [Volume]   [memory]  â”‚  â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                    â”‚                                          â”‚
                    â”‚  SWAP: 4GB  â”‚  DISK: 30GB gp3 (enc.)   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### DiseÃ±o de Red VPC (Preparado para ProducciÃ³n)

```
    VPC 10.0.0.0/16
    â”œâ”€â”€ Public Subnet A  (10.0.1.0/24)  â”€â”€â”€ AZ-a  â† EC2 instance aquÃ­
    â”œâ”€â”€ Public Subnet B  (10.0.2.0/24)  â”€â”€â”€ AZ-b  â† Preparada para ALB
    â”œâ”€â”€ Private Subnet A (10.0.10.0/24) â”€â”€â”€ AZ-a  â† Futuro: RDS, ElastiCache
    â””â”€â”€ Private Subnet B (10.0.11.0/24) â”€â”€â”€ AZ-b  â† Futuro: RDS replica
```

### Flujo de Datos entre Servicios

```
    Usuario
      â”‚
      â–¼
    Nginx â”€â”€â”€â”€â”€â–º N8n â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚                        â”‚  (webhooks, API calls)
      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â–º Chatwoot â—„â”€â”€â”€â”€â”˜
      â”‚            â”‚
      â”‚            â”œâ”€â”€â–º PostgreSQL (conversaciones, contactos)
      â”‚            â””â”€â”€â–º Redis (cache, colas Sidekiq)
      â”‚
      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â–º LibreChat â”€â”€â–º MongoDB (historial AI chats)
      â”‚            â”‚
      â”‚            â””â”€â”€â–º APIs externas (OpenAI, Anthropic, etc.)
      â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â–º Jupyter Connector
                   â”‚
                   â”œâ”€â”€â–º PostgreSQL (lectura de datos Chatwoot)
                   â”œâ”€â”€â–º MongoDB (lectura de datos LibreChat)
                   â””â”€â”€â–º Deepnote (consumo externo vÃ­a API)
```

---

## Stack TecnolÃ³gico

| Componente | Imagen Docker | VersiÃ³n | Puerto Interno |
|------------|--------------|---------|----------------|
| Nginx | `nginx:1.25-alpine` | 1.25.x | 80, 443 |
| N8n | `n8nio/n8n:latest` | Latest | 5678 |
| Chatwoot Web | `chatwoot/chatwoot:latest` | Latest | 3000 |
| Chatwoot Sidekiq | `chatwoot/chatwoot:latest` | Latest | â€” |
| LibreChat | `ghcr.io/danny-avila/librechat:latest` | Latest | 3080 |
| Jupyter | `jupyter/minimal-notebook:latest` | Latest | 8888 |
| PostgreSQL | `postgres:15-alpine` | 15.x | 5432 |
| MongoDB | `mongo:6.0` | 6.0.x | 27017 |
| Redis | `redis:7-alpine` | 7.x | 6379 |

---

## Despliegue RÃ¡pido

### Prerrequisitos

1. Cuenta AWS con acceso a la consola
2. Un **Key Pair** existente en la regiÃ³n objetivo
3. AWS CLI configurado (opcional, para despliegue por CLI)

### OpciÃ³n A: Despliegue via AWS Console

1. Navegar a **CloudFormation â†’ Create Stack â†’ Upload template**
2. Subir `cloudformation.yaml`
3. Configurar parÃ¡metros:
   - `KeyPairName`: seleccionar tu key pair
   - `SSHAllowedCIDR`: tu IP pÃºblica (ej: `203.0.113.50/32`)
   - `InstanceType`: `t3.micro` (Free Tier) o `t3.small` (recomendado)
4. Crear stack y esperar ~10 minutos
5. Revisar **Outputs** para obtener URLs

### OpciÃ³n B: Despliegue via CLI

```bash
aws cloudformation create-stack \
  --stack-name ai-ecosystem-sandbox \
  --template-body file://cloudformation.yaml \
  --parameters \
    ParameterKey=KeyPairName,ParameterValue=my-key \
    ParameterKey=SSHAllowedCIDR,ParameterValue=$(curl -s ifconfig.me)/32 \
    ParameterKey=InstanceType,ParameterValue=t3.micro \
    ParameterKey=SwapSizeGB,ParameterValue=4 \
  --capabilities CAPABILITY_NAMED_IAM \
  --region us-east-1

# Monitorear progreso
aws cloudformation wait stack-create-complete --stack-name ai-ecosystem-sandbox

# Obtener URLs
aws cloudformation describe-stacks --stack-name ai-ecosystem-sandbox \
  --query 'Stacks[0].Outputs' --output table
```

### VerificaciÃ³n Post-Despliegue

```bash
# SSH a la instancia
ssh -i my-key.pem ec2-user@<PUBLIC_IP>

# Verificar estado del stack
ecosystem status

# Ver logs en tiempo real
ecosystem logs

# Verificar salud de servicios
ecosystem health
```

---

## Estructura del Repositorio

```
ai-ecosystem/
â”œâ”€â”€ cloudformation.yaml      # IaC - Infraestructura completa AWS
â”œâ”€â”€ docker-compose.yml       # OrquestaciÃ³n de contenedores
â”œâ”€â”€ .env.example             # Variables de entorno (plantilla)
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ nginx.conf           # Reverse proxy con rate limiting
â”‚   â”œâ”€â”€ librechat.yaml       # ConfiguraciÃ³n de endpoints LLM
â”‚   â””â”€â”€ index.html           # Landing page / dashboard
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ stack-manager.sh     # CLI de gestiÃ³n (start/stop/backup)
â”‚
â””â”€â”€ README.md                # Esta documentaciÃ³n
```

---

## ConfiguraciÃ³n Detallada

### Nginx Reverse Proxy

El proxy implementa las siguientes medidas de seguridad y rendimiento:

- **Path-based routing**: `/n8n/`, `/chatwoot/`, `/chat/`, `/data/`
- **Rate limiting**: 10 req/s general, 30 req/s para APIs
- **WebSocket support**: para N8n, Chatwoot y LibreChat
- **Security headers**: X-Frame-Options, X-Content-Type-Options, CSP, XSS Protection
- **Gzip compression**: para reducir transferencia de datos
- **Bloqueo de rutas sensibles**: `.env`, `.git`, `.htaccess`

### Docker Networking

Se implementan **dos redes aisladas**:

- `frontend` (bridge): conecta Nginx con los servicios web (N8n, Chatwoot, LibreChat, Jupyter)
- `backend` (bridge, **internal**): conecta servicios con bases de datos. **No tiene acceso a internet**, lo cual impide que las bases de datos sean accesibles desde fuera del host.

### Persistencia de Datos

Cada base de datos utiliza **named Docker volumes**:

| Volume | Servicio | Contenido |
|--------|----------|-----------|
| `ai-eco-postgres` | PostgreSQL | Datos de Chatwoot |
| `ai-eco-mongo` | MongoDB | Historial de LibreChat |
| `ai-eco-n8n` | N8n | Workflows y credenciales |
| `ai-eco-librechat` | LibreChat | ImÃ¡genes subidas |
| `ai-eco-jupyter` | Jupyter | Notebooks de trabajo |

### Jupyter como Puente para Deepnote

El contenedor Jupyter actÃºa como **API Gateway seguro** con las siguientes caracterÃ­sticas:

1. Tiene acceso a la red `backend` donde residen las bases de datos
2. Expone un endpoint en `/data/` a travÃ©s de Nginx
3. Incluye pre-instalados: `psycopg2`, `pymongo`, `pandas`, `requests`
4. Deepnote se conecta vÃ­a REST API al endpoint pÃºblico, **sin exponer puertos de base de datos**

---

## AnÃ¡lisis de Recursos (Stress Test)

### Presupuesto de Memoria â€” t3.micro (1GB RAM + 4GB Swap)

| Servicio | LÃ­mite Docker | RSS Estimado Real | Notas |
|----------|:------------:|:-----------------:|-------|
| PostgreSQL | 200 MB | 80-120 MB | Tuned: shared_buffers=64MB, max_conn=50 |
| MongoDB | 256 MB | 120-180 MB | WiredTiger cache limitado a 100MB |
| Redis | 64 MB | 15-30 MB | maxmemory=50MB, sin persistencia |
| N8n | 300 MB | 100-180 MB | Node.js max-old-space=256MB |
| Chatwoot Web | 400 MB | 250-350 MB | Rails: WEB_CONCURRENCY=1, 3 threads |
| Chatwoot Sidekiq | 300 MB | 150-250 MB | MALLOC_ARENA_MAX=2 |
| LibreChat | 350 MB | 120-200 MB | Node.js max-old-space=256MB |
| Jupyter | 256 MB | 80-150 MB | Minimal notebook, pip packages |
| Nginx | 64 MB | 5-15 MB | Alpine, worker_connections=512 |
| **TOTAL** | **2,190 MB** | **920-1,475 MB** | |

### Estrategia de OptimizaciÃ³n Implementada

#### 1. Swap Agresivo (4GB)
El swap file de 4GB proporciona un colchÃ³n para picos de memoria. Con `vm.swappiness=60`, el kernel empezarÃ¡ a paginar procesos inactivos al swap antes de alcanzar OOM.

#### 2. LÃ­mites de Memoria Docker
Cada contenedor tiene `deploy.resources.limits.memory` configurado. Si un contenedor excede su lÃ­mite, Docker lo reinicia en lugar de afectar a otros servicios (fail-fast pattern).

#### 3. Tuning de Bases de Datos
- **PostgreSQL**: `shared_buffers=64MB` (vs default 128MB), `max_connections=50` (vs 100), `work_mem=2MB` (vs 4MB)
- **MongoDB**: `--wiredTigerCacheSizeGB 0.1` (100MB vs default que toma 50% de RAM)
- **Redis**: `--maxmemory 50mb`, sin persistencia a disco, evicciÃ³n LRU

#### 4. OptimizaciÃ³n de Application Servers
- Chatwoot: `WEB_CONCURRENCY=1` (1 worker vs default 2), `MALLOC_ARENA_MAX=2` (limita fragmentaciÃ³n glibc)
- N8n y LibreChat: `NODE_OPTIONS="--max-old-space-size=256"` limita el heap de V8
- Logs Docker: `max-size=10m, max-file=3` previene crecimiento de logs

### Veredicto Realista

> **âš ï¸ La t3.micro (1GB) puede arrancar el stack completo, pero NO es estable para uso continuado.**

Con el swap de 4GB, los 9 contenedores **arrancan exitosamente** y pueden responder a peticiones individuales durante testing. Sin embargo, bajo carga concurrente (>2-3 usuarios simultÃ¡neos), el exceso de swapping causa:
- Latencias de 5-30 segundos en respuestas
- Timeouts intermitentes en Chatwoot/LibreChat
- Riesgo de OOM-killer matando Sidekiq o MongoDB

### Dimensionamiento Recomendado

| Entorno | Instancia | RAM | Notas |
|---------|-----------|-----|-------|
| **Sandbox (demo personal)** | t3.micro | 1 GB | Funcional con swap, no para carga |
| **MVP mÃ­nimo viable** | t3.small | 2 GB | âœ… **MÃ­nimo recomendado** â€” estable para 3-5 usuarios |
| **Staging/QA** | t3.medium | 4 GB | CÃ³modo para testing con carga |
| **ProducciÃ³n (monolito)** | t3.large | 8 GB | Headroom para picos, no HA |

---

## Estrategia de ProducciÃ³n (HA)

### "Â¿CÃ³mo separar este monolito en Alta Disponibilidad?"

La migraciÃ³n a producciÃ³n implica descomponer el stack en servicios gestionados de AWS y contenedores orquestados:

### Arquitectura Objetivo

```
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚  Route 53   â”‚
                         â”‚  (DNS)      â”‚
                         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                         â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                         â”‚ CloudFront  â”‚
                         â”‚  (CDN+SSL)  â”‚
                         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Application Load    â”‚
                    â”‚   Balancer (ALB)      â”‚
                    â”‚   Multi-AZ            â”‚
                    â””â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
                        â”‚    â”‚    â”‚    â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â” â”Œâ–¼â”€â”€â”€â”€â–¼â” â”Œâ–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   ECS    â”‚ â”‚ ECS  â”‚ â”‚   ECS    â”‚
              â”‚ Fargate  â”‚ â”‚Fargatâ”‚ â”‚ Fargate  â”‚
              â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ â”‚â”€â”€â”€â”€â”€â”€â”‚ â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
              â”‚ Chatwoot â”‚ â”‚ N8n  â”‚ â”‚LibreChat â”‚
              â”‚ (2 tasks)â”‚ â”‚(1-2) â”‚ â”‚ (2 tasks)â”‚
              â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                   â”‚          â”‚          â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚              VPC Private Subnets       â”‚
          â”‚                                        â”‚
          â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
          â”‚ â”‚  RDS     â”‚ â”‚DocumentDBâ”‚ â”‚Elasti-  â”‚ â”‚
          â”‚ â”‚PostgreSQLâ”‚ â”‚(MongoDB) â”‚ â”‚Cache    â”‚ â”‚
          â”‚ â”‚Multi-AZ  â”‚ â”‚Replica   â”‚ â”‚(Redis)  â”‚ â”‚
          â”‚ â”‚          â”‚ â”‚Set       â”‚ â”‚Cluster  â”‚ â”‚
          â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Plan de MigraciÃ³n por Capas

#### Capa 1 â€” Bases de Datos Gestionadas (Prioridad Alta)

| Servicio Actual | MigraciÃ³n AWS | Beneficio |
|----------------|---------------|-----------|
| PostgreSQL container | **Amazon RDS PostgreSQL** (Multi-AZ) | Backups automÃ¡ticos, failover, encryption at rest |
| MongoDB container | **Amazon DocumentDB** | Compatibilidad MongoDB API, rÃ©plicas automÃ¡ticas |
| Redis container | **Amazon ElastiCache** (Redis) | Cluster mode, persistence, no memory management |

**JustificaciÃ³n**: Las bases de datos son el componente mÃ¡s crÃ­tico. Delegarlas a servicios gestionados elimina el riesgo de pÃ©rdida de datos por fallos del host y proporciona backups automÃ¡ticos.

#### Capa 2 â€” CÃ³mputo Orquestado (Prioridad Media)

| Componente | MigraciÃ³n AWS | ConfiguraciÃ³n |
|------------|---------------|---------------|
| Docker Compose | **ECS Fargate** | Sin gestiÃ³n de servidores |
| Cada servicio | **ECS Service** con auto-scaling | Min 2 tasks para HA |
| Nginx | **Application Load Balancer** | Health checks, SSL termination |

**JustificaciÃ³n**: ECS Fargate elimina la gestiÃ³n de instancias EC2 para contenedores. Cada servicio escala independientemente.

#### Capa 3 â€” Networking y Seguridad (Prioridad Alta)

- **VPC**: Mantener el diseÃ±o actual (ya tiene subnets multi-AZ)
- **ALB**: Reemplaza Nginx como punto de entrada (SSL termination, health checks nativos)
- **Security Groups**: Refinar para que solo ALB alcance ECS, y solo ECS alcance RDS/ElastiCache
- **AWS WAF**: ProtecciÃ³n contra ataques comunes (SQL injection, XSS)
- **ACM**: Certificados SSL gratuitos gestionados

#### Capa 4 â€” Observabilidad

| Necesidad | Servicio AWS |
|-----------|-------------|
| Logs centralizados | CloudWatch Logs + Log Insights |
| MÃ©tricas | CloudWatch Metrics + Custom dashboards |
| Alertas | CloudWatch Alarms â†’ SNS â†’ Email/Slack |
| Tracing distribuido | AWS X-Ray |

### EstimaciÃ³n de Costos Mensuales (ProducciÃ³n)

| Componente | EspecificaciÃ³n | Costo Estimado/mes |
|------------|---------------|:------------------:|
| ECS Fargate (4 services) | 0.5 vCPU, 1GB cada uno | ~$60 |
| RDS PostgreSQL | db.t3.micro, Multi-AZ | ~$30 |
| DocumentDB | db.t3.medium | ~$60 |
| ElastiCache Redis | cache.t3.micro | ~$15 |
| ALB | 1 LB + reglas | ~$20 |
| Data Transfer | ~50 GB/mes | ~$5 |
| CloudWatch | Logs + metrics | ~$10 |
| **Total** | | **~$200/mes** |

### Decisiones de DiseÃ±o para ProducciÃ³n

1. **Stateless services**: Chatwoot, LibreChat y N8n no guardan estado local â†’ escalan horizontalmente
2. **Blue/Green deployments**: ECS soporta rolling updates sin downtime
3. **Secrets Manager**: Migrar `.env` a AWS Secrets Manager con rotaciÃ³n automÃ¡tica
4. **ECR privado**: Almacenar imÃ¡genes custom en Amazon ECR (vs Docker Hub rate limits)
5. **CI/CD**: GitHub Actions â†’ ECR â†’ ECS (pipeline automatizado)

---

## OperaciÃ³n y Mantenimiento

### Comandos del Stack Manager

```bash
# Tras SSH a la instancia:
ecosystem start     # Iniciar todos los servicios
ecosystem stop      # Detener todos los servicios
ecosystem restart   # Reiniciar stack completo
ecosystem status    # Ver estado, memoria, disco
ecosystem logs      # Logs en tiempo real (todos)
ecosystem logs n8n  # Logs de un servicio especÃ­fico
ecosystem health    # Health check de todos los servicios
ecosystem backup    # Backup de PostgreSQL y MongoDB
```

### URLs de Acceso

| Servicio | URL | Credenciales |
|----------|-----|-------------|
| Dashboard | `http://<IP>/` | â€” |
| N8n | `http://<IP>/n8n/` | Ver `.env` (N8N_BASIC_AUTH_*) |
| Chatwoot | `http://<IP>/chatwoot/` | Crear en primer acceso |
| LibreChat | `http://<IP>/chat/` | Registrarse en primer acceso |
| Jupyter | `http://<IP>/data/` | Token en `.env` (JUPYTER_TOKEN) |

### Backups

Los backups se ejecutan manualmente con `ecosystem backup` y se almacenan en `/opt/ai-ecosystem/backups/`. Para producciÃ³n, se recomienda automatizar con cron:

```bash
# Agregar a /etc/cron.d/ai-ecosystem-backup
0 2 * * * root /opt/ai-ecosystem/scripts/stack-manager.sh backup
```

---

## Seguridad

### Medidas Implementadas

| Capa | Medida | Detalle |
|------|--------|---------|
| Red | VPC aislada | Subnets privadas para futuras DBs gestionadas |
| Red | Security Groups | Solo puertos 80, 443, 22 abiertos |
| Red | Docker internal network | Backend network sin acceso externo |
| AplicaciÃ³n | Nginx rate limiting | 10-30 req/s por IP |
| AplicaciÃ³n | Security headers | X-Frame, CSP, XSS protection |
| AplicaciÃ³n | Bloqueo de rutas | .env, .git, .htaccess bloqueados |
| Datos | EBS encryption | Disco cifrado por defecto |
| Datos | Passwords autogenerados | openssl rand para cada secreto |
| Datos | .env con chmod 600 | Solo root puede leer credenciales |
| Acceso | SSH restringido | CIDR configurable en CloudFormation |
| Acceso | IAM role | SSM habilitado (alternativa a SSH) |

### Recomendaciones para ProducciÃ³n

1. **Restringir SSH CIDR** a la IP especÃ­fica del equipo
2. **Habilitar SSL** con Let's Encrypt (Certbot) o AWS ACM
3. **Configurar MFA** para acceso a la consola AWS
4. **RotaciÃ³n de secretos** periÃ³dica o vÃ­a AWS Secrets Manager
5. **Habilitar VPC Flow Logs** para auditorÃ­a de red
6. **AWS GuardDuty** para detecciÃ³n de amenazas

---

## Troubleshooting

### El stack no arranca completamente

```bash
# Ver quÃ© contenedores fallaron
docker compose ps

# Ver logs del servicio que fallÃ³
docker compose logs <servicio> --tail=100

# Verificar memoria disponible
free -h

# Si hay OOM, verificar cuÃ¡l fue matado
dmesg | grep -i "out of memory" | tail -5
```

### Chatwoot muestra error de migraciÃ³n

```bash
# Ejecutar migraciones manualmente
docker exec chatwoot-web bundle exec rails db:prepare
docker compose restart chatwoot-web chatwoot-sidekiq
```

### MongoDB no arranca (WiredTiger error)

```bash
# Limpiar lock files
docker compose stop mongodb
docker volume rm ai-eco-mongo
docker compose up -d mongodb
```

### Rendimiento muy lento

```bash
# Verificar uso de swap
ecosystem status

# Si swap > 50%, considerar:
# 1. Parar servicios no esenciales temporalmente
docker compose stop jupyter-connector

# 2. O migrar a t3.small
# Cambiar InstanceType en CloudFormation y hacer Update Stack
```

### Verificar logs del UserData (primer despliegue)

```bash
# El script de inicializaciÃ³n guarda log en:
cat /var/log/user-data.log

# Verificar si completÃ³ exitosamente
tail -5 /var/log/user-data.log
# Debe mostrar: "=== Setup Complete: ... ==="
```

---

## Licencia

Este proyecto es una prueba tÃ©cnica. Los servicios individuales (N8n, Chatwoot, LibreChat) mantienen sus respectivas licencias open-source.

---

